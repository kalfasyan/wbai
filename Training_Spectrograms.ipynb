{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# from tqdm.notebook import tqdm as tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset, ConcatDataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import datasets, transforms\n",
    "from torchaudio.transforms import Spectrogram, AmplitudeToDB\n",
    "\n",
    "# torchaudio.USE_SOUNDFILE_LEGACY_INTERFACE = False\n",
    "torchaudio.set_audio_backend('sox_io')\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import psutil\n",
    "import requests\n",
    "\n",
    "from utils import *\n",
    "from wingbeat_datasets import *\n",
    "from wingbeat_models import *\n",
    "\n",
    "# print(f'Total RAM      : {bytes2GB(psutil.virtual_memory().total):5.2f} GB')\n",
    "# print(f'Available RAM  : {bytes2GB(psutil.virtual_memory().available):5.2f} GB\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 35\n",
    "batch_size = 32\n",
    "batch_size_val = batch_size * 2\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "num_workers = psutil.cpu_count()\n",
    "random_seed= 42\n",
    "setting = 'stft'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets and Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29002 in dataset: Melanogaster_RL/Y, and 1 label(s): ['D. melanogaster']\n",
      "Label(s) changed to [0]\n",
      "Nr. of valid wingbeats: 12819\n",
      "Found 24763 in dataset: Melanogaster_RL/Z, and 1 label(s): ['D. melanogaster']\n",
      "Label(s) changed to [0]\n",
      "Nr. of valid wingbeats: 11778\n",
      "Found 25732 in dataset: Suzukii_RL/Y, and 1 label(s): ['D. suzukii']\n",
      "Label(s) changed to [1]\n",
      "Nr. of valid wingbeats: 17088\n",
      "Found 14348 in dataset: Suzukii_RL/R, and 1 label(s): ['D. suzukii']\n",
      "Label(s) changed to [1]\n",
      "Nr. of valid wingbeats: 10372\n"
     ]
    }
   ],
   "source": [
    "dmel1 = WingbeatsDataset(dsname=\"Melanogaster_RL/Y\", custom_label=[0], transform=transforms.Compose([FilterWingbeat(setting='bandpass'), NormalizeWingbeat(), TransformWingbeat(setting=setting)])).clean()\n",
    "dmel2 = WingbeatsDataset(dsname=\"Melanogaster_RL/Z\", custom_label=[0], transform=transforms.Compose([FilterWingbeat(setting='bandpass'), NormalizeWingbeat(), TransformWingbeat(setting=setting)])).clean()\n",
    "dsuz1 = WingbeatsDataset(dsname=\"Suzukii_RL/Y\",      custom_label=[1], transform=transforms.Compose([FilterWingbeat(setting='bandpass'), NormalizeWingbeat(), TransformWingbeat(setting=setting)])).clean()\n",
    "dsuz2 = WingbeatsDataset(dsname=\"Suzukii_RL/R\",      custom_label=[1], transform=transforms.Compose([FilterWingbeat(setting='bandpass'), NormalizeWingbeat(), TransformWingbeat(setting=setting)])).clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_dataset = ConcatDataset([dmel1, dsuz1])\n",
    "\n",
    "train_size = int(0.8 * len(transformed_dataset))\n",
    "valid_size = len(transformed_dataset) - train_size\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(transformed_dataset, [train_size, valid_size])\n",
    "test_dataset = ConcatDataset([dmel2, dsuz2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size_val, num_workers=num_workers)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size_val, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet34, densenet121, resnet152\n",
    "import torch.optim as optim\n",
    "\n",
    "if setting.startswith('psd'):\n",
    "    model = Conv1dNetPSD()\n",
    "elif setting == 'raw':\n",
    "    model = Conv1dNetRAW()\n",
    "elif setting == 'stft':\n",
    "    model = resnet152(pretrained=False)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs,2)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, betas=(0.9, 0.999))\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True)\n",
    "early_stopping = EarlyStopping(patience=7, verbose=2)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on gpu: True\n"
     ]
    }
   ],
   "source": [
    "# Choosing whether to train on a gpu\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "print(f'Train on gpu: {train_on_gpu}')# Number of gpus\n",
    "model = model.to('cuda', dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 748/748 [03:31<00:00,  3.54it/s]\n",
      "Validating..\t: 100%|██████████| 94/94 [00:45<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.777387).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t:   0%|          | 0/748 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train_acc: 62.21% loss: 0.651,  val_loss: 0.777 val_acc: 62.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 748/748 [03:14<00:00,  3.85it/s]\n",
      "Validating..\t: 100%|██████████| 94/94 [00:12<00:00,  7.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.777387 --> 0.609581).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t:   0%|          | 0/748 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_acc: 62.70% loss: 0.661,  val_loss: 0.610 val_acc: 63.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 748/748 [03:15<00:00,  3.83it/s]\n",
      "Validating..\t: 100%|██████████| 94/94 [00:12<00:00,  7.65it/s]\n",
      "Training..\t:   0%|          | 0/748 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 2: train_acc: 64.78% loss: 0.410,  val_loss: 0.996 val_acc: 57.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 748/748 [03:14<00:00,  3.84it/s]\n",
      "Validating..\t: 100%|██████████| 94/94 [00:12<00:00,  7.65it/s]\n",
      "Training..\t:   0%|          | 0/748 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch 3: train_acc: 79.93% loss: 0.338,  val_loss: 0.787 val_acc: 70.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 748/748 [03:14<00:00,  3.84it/s]\n",
      "Validating..\t: 100%|██████████| 94/94 [00:12<00:00,  7.68it/s]\n",
      "Training..\t:   0%|          | 0/748 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 3 out of 7\n",
      "Epoch 4: train_acc: 82.31% loss: 0.257,  val_loss: 0.858 val_acc: 66.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 748/748 [03:14<00:00,  3.84it/s]\n",
      "Validating..\t: 100%|██████████| 94/94 [00:12<00:00,  7.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.609581 --> 0.394731).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t:   0%|          | 0/748 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: train_acc: 83.77% loss: 0.295,  val_loss: 0.395 val_acc: 84.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 748/748 [03:13<00:00,  3.86it/s]\n",
      "Validating..\t: 100%|██████████| 94/94 [00:12<00:00,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.394731 --> 0.249302).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t:   0%|          | 0/748 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: train_acc: 85.03% loss: 0.311,  val_loss: 0.249 val_acc: 85.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 748/748 [03:14<00:00,  3.85it/s]\n",
      "Validating..\t: 100%|██████████| 94/94 [00:12<00:00,  7.73it/s]\n",
      "Training..\t:   0%|          | 0/748 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch 7: train_acc: 85.54% loss: 0.256,  val_loss: 0.279 val_acc: 86.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 748/748 [03:14<00:00,  3.85it/s]\n",
      "Validating..\t: 100%|██████████| 94/94 [00:12<00:00,  7.66it/s]\n",
      "Training..\t:   0%|          | 0/748 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch 8: train_acc: 86.16% loss: 0.242,  val_loss: 0.312 val_acc: 86.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 748/748 [03:14<00:00,  3.85it/s]\n",
      "Validating..\t: 100%|██████████| 94/94 [00:12<00:00,  7.67it/s]\n",
      "Training..\t:   0%|          | 0/748 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 3 out of 7\n",
      "Epoch 9: train_acc: 86.49% loss: 0.240,  val_loss: 0.459 val_acc: 83.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 748/748 [03:13<00:00,  3.86it/s]\n",
      "Validating..\t: 100%|██████████| 94/94 [00:12<00:00,  7.68it/s]\n",
      "Training..\t:   0%|          | 0/748 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    11: reducing learning rate of group 0 to 1.0000e-03.\n",
      "EarlyStopping counter: 4 out of 7\n",
      "Epoch 10: train_acc: 87.05% loss: 0.257,  val_loss: 1.128 val_acc: 71.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 748/748 [03:14<00:00,  3.85it/s]\n",
      "Validating..\t: 100%|██████████| 94/94 [00:12<00:00,  7.66it/s]\n",
      "Training..\t:   0%|          | 0/748 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 5 out of 7\n",
      "Epoch 11: train_acc: 88.75% loss: 0.236,  val_loss: 0.259 val_acc: 87.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 748/748 [03:14<00:00,  3.85it/s]\n",
      "Validating..\t: 100%|██████████| 94/94 [00:12<00:00,  7.63it/s]\n",
      "Training..\t:   0%|          | 0/748 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 6 out of 7\n",
      "Epoch 12: train_acc: 89.46% loss: 0.240,  val_loss: 0.262 val_acc: 87.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training..\t: 100%|██████████| 748/748 [03:13<00:00,  3.86it/s]\n",
      "Validating..\t: 100%|██████████| 94/94 [00:12<00:00,  7.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 7 out of 7\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Model training\n",
    "for epoch in range(num_epochs):\n",
    "    # Going through the training set\n",
    "    correct_train = 0\n",
    "    model.train()\n",
    "    for x_batch,y_batch,path_batch,idx_batch in tqdm(train_dataloader, desc='Training..\\t'):        \n",
    "\n",
    "        y_batch = torch.as_tensor(y_batch).type(torch.LongTensor)\n",
    "        x_batch,y_batch = x_batch.cuda(), y_batch.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x_batch)\n",
    "        loss = criterion(pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        correct_train += (pred.argmax(axis=1) == y_batch).float().sum().item()\n",
    "\n",
    "    train_accuracy = correct_train / (len(train_dataloader)*batch_size) * 100.\n",
    "    # Going through the validation set\n",
    "    correct_valid = 0\n",
    "    model.eval()\n",
    "    for x_batch,y_batch,path_batch,idx_batch in tqdm(valid_dataloader, desc='Validating..\\t'):\n",
    "        \n",
    "        y_batch = torch.as_tensor(y_batch).type(torch.LongTensor)\n",
    "        x_batch,y_batch = x_batch.cuda(), y_batch.cuda()\n",
    "\n",
    "        pred = model(x_batch)\n",
    "        val_loss = criterion(pred, y_batch)\n",
    "        correct_valid += (pred.argmax(axis=1) == y_batch).float().sum().item()\n",
    "    valid_accuracy = correct_valid / (len(valid_dataloader)*batch_size_val) * 100.\n",
    "    scheduler.step(val_loss)\n",
    "    early_stopping(val_loss, model)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "        # Printing results\n",
    "    print(f\"Epoch {epoch}: train_acc: {train_accuracy:.2f}% loss: {loss:.3f},  val_loss: {val_loss:.3f} val_acc: {valid_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(x_batch, y_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing..\t: 100%|██████████| 347/347 [00:50<00:00,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.77125360230548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "correct_test = 0\n",
    "model.eval()\n",
    "for x_batch,y_batch,path_batch,idx_batch in tqdm(test_dataloader, desc=\"Testing..\\t\"):\n",
    "\n",
    "    y_batch = torch.as_tensor(y_batch).type(torch.LongTensor)\n",
    "    x_batch,y_batch = x_batch.cuda(), y_batch.cuda()\n",
    "\n",
    "    pred = model(x_batch)\n",
    "    val_loss = criterion(pred, y_batch)\n",
    "    correct_test += (pred.argmax(axis=1) == y_batch).float().sum().item()\n",
    "test_accuracy = correct_test / (len(test_dataloader)*batch_size_val) * 100.\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_all_preds(model, loader):\n",
    "    all_preds = torch.tensor([])\n",
    "    for x_batch,y_batch,path_batch,idx_batch in loader:\n",
    "\n",
    "        preds = model(x_batch.float())\n",
    "        all_preds = torch.cat(\n",
    "            (all_preds, preds)\n",
    "            ,dim=0\n",
    "        )\n",
    "    return all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_preds(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
