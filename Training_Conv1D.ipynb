{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kalfasyan/anaconda3/envs/wbai/lib/python3.6/site-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  '\"sox\" backend is being deprecated. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total RAM      : 31.21 GB\n",
      "Available RAM  : 26.03 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# from tqdm.notebook import tqdm as tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset, ConcatDataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import datasets, transforms\n",
    "from tsai.all import *\n",
    "\n",
    "torchaudio.USE_SOUNDFILE_LEGACY_INTERFACE = False\n",
    "torchaudio.set_audio_backend('soundfile')\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import psutil\n",
    "import requests\n",
    "\n",
    "from utils import *\n",
    "from wingbeat_datasets import *\n",
    "from wingbeat_models import *\n",
    "\n",
    "print(f'Total RAM      : {bytes2GB(psutil.virtual_memory().total):5.2f} GB')\n",
    "print(f'Available RAM  : {bytes2GB(psutil.virtual_memory().available):5.2f} GB\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 35\n",
    "batch_size = 32\n",
    "batch_size_val = batch_size * 2\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "num_workers = psutil.cpu_count()\n",
    "random_seed= 42\n",
    "setting = 'raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29002 in dataset: Melanogaster_RL/Y, and 1 label(s): ['Y']\n",
      "Label(s) changed to [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1813 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29002 in dataset: Melanogaster_RL/Y, and 1 label(s): ['Y']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1813/1813 [01:17<00:00, 23.28it/s]\n",
      "  0%|          | 0/1548 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24763 in dataset: Melanogaster_RL/Z, and 1 label(s): ['Z']\n",
      "Label(s) changed to [0]\n",
      "Found 24763 in dataset: Melanogaster_RL/Z, and 1 label(s): ['Z']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 989/1548 [00:43<00:24, 22.74it/s]"
     ]
    }
   ],
   "source": [
    "dmel1 = WingbeatsDataset(dsname=\"Melanogaster_RL/Y\", custom_label=[0], transform=transforms.Compose([FilterWingbeat(setting='bandpass'), TransformWingbeat(setting=setting)])).clean()\n",
    "dmel2 = WingbeatsDataset(dsname=\"Melanogaster_RL/Z\", custom_label=[0], transform=transforms.Compose([FilterWingbeat(setting='bandpass'), TransformWingbeat(setting=setting)])).clean()\n",
    "dsuz1 = WingbeatsDataset(dsname=\"Suzukii_RL/L\",      custom_label=[1], transform=transforms.Compose([FilterWingbeat(setting='bandpass'), TransformWingbeat(setting=setting)])).clean()\n",
    "dsuz2 = WingbeatsDataset(dsname=\"Suzukii_RL/R\",      custom_label=[1], transform=transforms.Compose([FilterWingbeat(setting='bandpass'), TransformWingbeat(setting=setting)])).clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_dataset = ConcatDataset([dmel1, dsuz1])\n",
    "\n",
    "train_size = int(0.8 * len(transformed_dataset))\n",
    "valid_size = len(transformed_dataset) - train_size\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(transformed_dataset, [train_size, valid_size])\n",
    "test_dataset = ConcatDataset([dmel2, dsuz2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size_val, num_workers=num_workers)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size_val, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if setting.startswith('psd'):\n",
    "    model = Conv1dNetPSD()\n",
    "else:\n",
    "    model = Conv1dNetRAW()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, betas=(0.9, 0.999))\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True)\n",
    "early_stopping = EarlyStopping(patience=7, verbose=False)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import preprocessing\n",
    "# import itertools\n",
    "\n",
    "# le = preprocessing.LabelEncoder()\n",
    "# all_labels = [transformed_dataset.datasets[i].labels for i in range(len(transformed_dataset.datasets))]\n",
    "# all_labels = list(itertools.chain.from_iterable(all_labels))\n",
    "# le.fit(all_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing whether to train on a gpu\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "print(f'Train on gpu: {train_on_gpu}')# Number of gpus\n",
    "model = model.to('cuda', dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training\n",
    "for epoch in range(num_epochs):\n",
    "    # Going through the training set\n",
    "    correct_train = 0\n",
    "    model.train()\n",
    "    for x_batch,y_batch,path_batch,idx_batch in tqdm(train_dataloader, desc='Training..\\t'):        \n",
    "\n",
    "        y_batch = torch.as_tensor(y_batch).type(torch.LongTensor)\n",
    "        x_batch,y_batch = x_batch.cuda(), y_batch.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x_batch)\n",
    "        loss = criterion(pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        correct_train += (pred.argmax(axis=1) == y_batch).float().sum().item()\n",
    "\n",
    "    train_accuracy = correct_train / (len(train_dataloader)*batch_size) * 100.\n",
    "    # Going through the validation set\n",
    "    correct_valid = 0\n",
    "    model.eval()\n",
    "    for x_batch,y_batch,path_batch,idx_batch in tqdm(valid_dataloader, desc='Validating..\\t'):\n",
    "        \n",
    "        y_batch = torch.as_tensor(y_batch).type(torch.LongTensor)\n",
    "        x_batch,y_batch = x_batch.cuda(), y_batch.cuda()\n",
    "\n",
    "        pred = model(x_batch)\n",
    "        val_loss = criterion(pred, y_batch)\n",
    "        correct_valid += (pred.argmax(axis=1) == y_batch).float().sum().item()\n",
    "    valid_accuracy = correct_valid / (len(valid_dataloader)*batch_size_val) * 100.\n",
    "    scheduler.step(val_loss)\n",
    "    early_stopping(val_loss, model)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "        # Printing results\n",
    "    print(f\"Epoch {epoch}: train_acc: {train_accuracy:.2f}% loss: {loss:.3f},  val_loss: {val_loss:.3f} val_acc: {valid_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_test = 0\n",
    "model.eval()\n",
    "for x_batch,y_batch,path_batch,idx_batch in test_dataloader:\n",
    "\n",
    "    y_batch = torch.as_tensor(y_batch).type(torch.LongTensor)\n",
    "    x_batch,y_batch = x_batch.cuda(), y_batch.cuda()\n",
    "\n",
    "    pred = model(x_batch)\n",
    "    val_loss = criterion(pred, y_batch)\n",
    "    correct_test += (pred.argmax(axis=1) == y_batch).float().sum().item()\n",
    "test_accuracy = correct_test / (len(test_dataloader)*batch_size_val) * 100.\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
